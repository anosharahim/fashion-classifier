{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d69758a7",
   "metadata": {},
   "source": [
    "# Classifiying Men's and Women's Fashion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a3c0c85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary packages and libraries\n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea49d15b",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "This step entails extracting the images from the zipped files, opening each image file, converting it into an array format, resizing it to have the same shape, adding class labels for classification purposes, and eventually merging and shuffling the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d0bd27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "men: 1242 | women: 1270\n",
      "total: 2512\n"
     ]
    }
   ],
   "source": [
    "#extract images from zipped files \n",
    "with zipfile.ZipFile(\"female-clothing.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall()\n",
    "with zipfile.ZipFile(\"male-clothing.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall()\n",
    "    \n",
    "#get image file paths \n",
    "m_files = os.listdir('../fashion-classifier/men')\n",
    "w_files = os.listdir('../fashion-classifier/women')\n",
    "print('men:',len(m_files),'| women:',len(w_files))\n",
    "\n",
    "#merge both datasets \n",
    "all_files = m_files + w_files\n",
    "print('total:',len(all_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbf77dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert image files into arrays\n",
    "def read_img(file,name):\n",
    "    images = np.zeros((14700))\n",
    "    for image in file: \n",
    "        arr = Image.open(name+'/'+image) #get img array \n",
    "        img = arr.resize((70,70)) #resize for standard sizing\n",
    "        arr = np.asarray(img) #turn into array\n",
    "        img.close()\n",
    "        flatten = arr.flatten() #flatten\n",
    "        images = np.vstack((images,flatten)) #stack \n",
    "    images = np.delete(images, 0, 0)\n",
    "    return images\n",
    "\n",
    "#read images from files \n",
    "men = read_img(m_files[:500],'men')\n",
    "women = read_img(w_files[:500],'women')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d674206e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn into dataframes and add class labels\n",
    "men = pd.DataFrame(men)\n",
    "men['label'] = 0\n",
    "women = pd.DataFrame(women)\n",
    "women['label'] = 1\n",
    "\n",
    "#merge and shuffle\n",
    "fashion = men.append(women,ignore_index=True)\n",
    "fashion = shuffle(fashion)\n",
    "\n",
    "#separate dependent and independent variables\n",
    "X = fashion.loc[:, fashion.columns != 'label']\n",
    "y = fashion['label']\n",
    "\n",
    "#see dataframe\n",
    "fashion.head()\n",
    "\n",
    "#split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.50, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97be705",
   "metadata": {},
   "source": [
    "## Classification using SVC \n",
    "\n",
    "The classification pipeline consists of a StandardScaler() which removes the mean and scaling to unit variance, which helps ensure that the individual features are more or less normally distributed, preventing the model from behaving badly as a result of some features that would otherwise dominate the objective function. The model used is a Support Vector Classifier with a linear kernel, and consists of the regularization parameter C. This is set to 0.2, which is relatively strong, to prevent the model from overfitting. This is useful, especially when classifying on the original pixel data, since there can be a lot of unnecessary noise that the model could try to learn. Lastly, I checked model accuracy both with and without cross validation to get an idea for how much overfitting might still be present. \n",
    "\n",
    "\n",
    "### Classifying Original Pixel Data\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f73cad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC score: 1.0\n",
      "CV average score: 0.59\n"
     ]
    }
   ],
   "source": [
    "svc = make_pipeline(StandardScaler(), LinearSVC(random_state=0, C=.2))\n",
    "svc.fit(X_train, y_train)\n",
    "ypred = svc.predict(X_test)\n",
    "\n",
    "cv_scores = cross_val_score(svc, X_train, y_train, cv=10)\n",
    "print('SVC score:',svc.score(X_train, y_train))\n",
    "print(\"CV average score: %.2f\" % cv_scores.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d365417",
   "metadata": {},
   "source": [
    "Fitting the model on raw pixel data yields unexpected good accuracy score of 1, contrasted with a 0.59 when the score is checked with cross validation. This indicates that there was overfitting on the original data. This makes intuitive sense, since the raw pixel data probably has a number of features that didn't have as much predictive power as others, but the model trained on them anyways. Overall precision, accuracy, and recall revolves around 60%, which suggests that the model learned some difference between women and men's fashion, but might not be a reliable classifier with accurately classifying them. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f2e7c8",
   "metadata": {},
   "source": [
    "### Classifying PCA representations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dcc1b23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC score: 0.66\n",
      "CV average score: 0.64\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(8)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "svc.fit(X_train_pca, y_train)\n",
    "ypred = svc.predict(X_test_pca)\n",
    "\n",
    "cv_scores = cross_val_score(svc, X_train_pca, y_train, cv=7)\n",
    "\n",
    "print('SVC score:',svc.score(X_train_pca, y_train))\n",
    "print(\"CV average score: %.2f\" % cv_scores.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5494b9c9",
   "metadata": {},
   "source": [
    "In applying PCA, after using about 6-8 components, the error rates stopped improving, which suggests that these components have more explanatory power than the rest of the features. As expected, the difference between accuracy and cross-validated accuracy decreased, representing a decrease in overfitting as a result of using eigenvectors as feature representations. This was dependent on how many components were used. The overfitting level increased as more components were used, and than 8 components seemed to be the optimal number of eigenvectors to minimize overfitting and maximize accuracy. However, the improvement in accuracy was not by a huge margin than using raw data, which might suggest that while PCA could provide improvement in the error rates by training on useful feature representations, that the model could still really only learn to classify not more than ~64% accurately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7946771",
   "metadata": {},
   "source": [
    "### Classifying LDA representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b7bbcc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC score: 0.902\n",
      "CV average score: 0.90\n"
     ]
    }
   ],
   "source": [
    "lda = LDA()\n",
    "X_train_lda = lda.fit_transform(X_train,y_train)\n",
    "X_test_lda = lda.transform(X_test)\n",
    "\n",
    "svc.fit(X_train_lda, y_train)\n",
    "ypred_ = svc.predict(X_test_lda)\n",
    "\n",
    "cv_scores = cross_val_score(svc, X_train_lda, y_train, cv=10)\n",
    "\n",
    "print('SVC score:',svc.score(X_train_lda, y_train))\n",
    "print(\"CV average score: %.2f\" % cv_scores.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb154326",
   "metadata": {},
   "source": [
    "The Linear Discriminant Analysis provided a significant improvement in the accuracy score while ensuring that the model is not overfit or undefit. This might be attributed to the fact that LDA tries to expressedly find linear combinations of features that could separate classes, and this supervised dimensionality reduction method then performs better on fashion data, which may not always have a clearly defined separation. While PCA could look for all kinds of patterns in an unsupervised fashion, and there may well be all kinds of patterns in the feature data, in this classification task, we are more concerned with the categories of men's vs women's fashion, instead of the myriad other patterns that are no doubt present. LDA takes our priority of these classes into account while extracting useful linear combinations of features in a supervised manner, and as a result, provides better error rates than the Principal Component Analysis. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
