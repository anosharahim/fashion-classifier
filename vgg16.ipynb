{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "vgg16.ipynb",
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Comparing SVM and VGG16\n"
      ],
      "metadata": {
        "id": "xx5LSqknUMOl"
      },
      "id": "xx5LSqknUMOl"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEPhwNaBUsV_",
        "outputId": "23c9a299-173f-4c50-a55f-c31d746f8b9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "CEPhwNaBUsV_",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYshHa96WiIR"
      },
      "source": [
        "import zipfile\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn import svm\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "id": "LYshHa96WiIR",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing\n"
      ],
      "metadata": {
        "id": "SwelEX7HUIEc"
      },
      "id": "SwelEX7HUIEc"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1HcXN4xVW5N"
      },
      "source": [
        "m_files = os.listdir('/content/drive/MyDrive/fashion-data/men')\n",
        "w_files = os.listdir('/content/drive/MyDrive/fashion-data/women')\n",
        "all_files = m_files + w_files\n",
        "\n",
        "#convert image files into arrays\n",
        "path = '/content/drive/MyDrive/fashion-data'\n",
        "def read_img(file,name,pth):\n",
        "    images = np.zeros((14700))\n",
        "    for image in file: \n",
        "        arr = Image.open(pth+'/'+name+'/'+image) #get img array \n",
        "        img = arr.resize((70,70)) #resize for standard sizing\n",
        "        arr = np.asarray(img) #turn into array\n",
        "        img.close()\n",
        "        flatten = arr.flatten() #flatten\n",
        "        images = np.vstack((images,flatten)) #stack \n",
        "    images = np.delete(images, 0, 0)\n",
        "    return images\n",
        "\n",
        "#read images from files \n",
        "men = read_img(m_files[:500],'men',path)\n",
        "women = read_img(w_files[:500],'women',path)\n",
        "\n",
        "#turn into dataframes and add class labels\n",
        "men = pd.DataFrame(men)\n",
        "men['label'] = 0\n",
        "women = pd.DataFrame(women)\n",
        "women['label'] = 1\n",
        "\n",
        "#merge and shuffle\n",
        "fashion = men.append(women,ignore_index=True)\n",
        "fashion = shuffle(fashion)\n",
        "\n",
        "#separate dependent and independent variables\n",
        "X_ = fashion.loc[:, fashion.columns != 'label']\n",
        "y_ = fashion['label']\n",
        "\n",
        "#see dataframe\n",
        "fashion.head()\n",
        "\n",
        "#split dataset\n",
        "X_train_, X_test_, y_train_, y_test_ = train_test_split(X_, y_, test_size=0.50, random_state=42)\n"
      ],
      "id": "v1HcXN4xVW5N",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Support Vector Machines\n",
        "- Train a support vector classifier using each of the following kernels:\n",
        "    - Linear\n",
        "    - Poly (degree = 2)\n",
        "    - RBF\n",
        "\n",
        "- If you encounter any issues with training time or memory issues, then you may use a reduced dataset, but carefully detail why and how you reduced the dataset. Unnecessarily reducing the dataset will result in reduced grades!\n",
        "- Report your error rates on the testing dataset for the different kernels.\n"
      ],
      "metadata": {
        "id": "vrIzIrbaT0e-"
      },
      "id": "vrIzIrbaT0e-"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTddLftvVhPd",
        "outputId": "2cf1212d-f335-4a21-d3ac-2c28a36b0797",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "## LINEAR\n",
        "svm_linear = svm.SVC(kernel='linear')\n",
        "svm_linear.fit(X_train_,y_train_)\n",
        "## POLY\n",
        "svm_poly = svm.SVC(kernel='poly', degree=2)\n",
        "svm_poly.fit(X_train_,y_train_)\n",
        "## RBF\n",
        "svm_rbf = svm.SVC(kernel='rbf')\n",
        "svm_rbf.fit(X_train_,y_train_)\n",
        "\n",
        "print(\"Accuracy for kernel=POLY\",svm_poly.score(X_test_,y_test_)*100,'%')\n",
        "print(\"Accuracy for kernel=LINEAR\",svm_linear.score(X_test_,y_test_)*100,'%')\n",
        "print(\"Accuracy for kernel=POLY\",svm_rbf.score(X_test_,y_test_)*100,'%')"
      ],
      "id": "ZTddLftvVhPd",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for kernel=POLY 62.2 %\n",
            "Accuracy for kernel=LINEAR 56.8 %\n",
            "Accuracy for kernel=POLY 66.0 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Deep Neural Networks\n",
        "\n",
        "I perform transfer learning with VGG16, which is the convolutional neural network that won ImageNet 2014.. The chosen loss function is binary cross entropy, which adds the log probabilities of belonging to each category for each datapoint. It is effective in accurately classifying data because it penalizes smaller probabilities more. Binary cross entropy is an appropriate loss function for our task because we are classifying photos into binary categories of male and female fashion. \n"
      ],
      "metadata": {
        "id": "fT-mVMpcT_v9"
      },
      "id": "fT-mVMpcT_v9"
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.applications.vgg16 import decode_predictions\n",
        "from keras import models\n",
        "from keras import optimizers\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "GGYaNfb5Ct-W"
      },
      "id": "GGYaNfb5Ct-W",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prepaare images in bulk for VGG model\n",
        "def get_features(files,class_,path_):\n",
        "  features_ = []\n",
        "\n",
        "  for i in files: \n",
        "    ipath = path_+class_+i\n",
        "    im = load_img(ipath, target_size=(224, 224))\n",
        "    # convert the image pixels to a numpy array\n",
        "    im = img_to_array(im)\n",
        "    # reshape data for the model\n",
        "    im = im.reshape((1, im.shape[0], im.shape[1], im.shape[2]))\n",
        "    # prepare the image for the VGG model\n",
        "    im = preprocess_input(im)\n",
        "\n",
        "    features = model.predict(im)\n",
        "    features_.append(features)\n",
        "  \n",
        "  return features_\n",
        "\n",
        "#get features from files\n",
        "path_ = '/content/drive/MyDrive/fashion-data'\n",
        "men_ = get_features(m_files[:500],'/men/',path_)\n",
        "women_ = get_features(w_files[:500],'/women/',path_)\n",
        "\n",
        "#convert list to arrays\n",
        "men_ = np.asarray(men_)\n",
        "women_ = np.asarray(women_)\n",
        "#reshape into compatible format\n",
        "men_ = men_.reshape(len(men_), 10, 10, 10)\n",
        "women_ = women_.reshape(len(women_), 10, 10, 10)\n",
        "#define X and y variables\n",
        "X = np.append(men_, women_, axis = 0)\n",
        "y = np.append(np.ones(len(men_)), np.zeros(len(women_)), axis = 0)\n",
        "#split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
      ],
      "metadata": {
        "id": "Piof2tyZ9AZ5"
      },
      "id": "Piof2tyZ9AZ5",
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neuralnetwork = models.Sequential()\n",
        "neuralnetwork.compile(optimizer=tf.optimizers.Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "neuralnetwork.add(layers.Flatten(input_shape=(10,10,10)))\n",
        "neuralnetwork.add(layers.Dense(256, activation='relu', input_dim=(10*10*10)))\n",
        "neuralnetwork.add(layers.Dropout(0.5))\n",
        "neuralnetwork.add(layers.Dense(1, activation='sigmoid'))\n",
        "history = neuralnetwork.fit(X_train, y_train, epochs=50, validation_data = (X_test,y_test))\n"
      ],
      "metadata": {
        "id": "UK5w2Geb_3dw",
        "outputId": "7ded2e0e-39c6-46e6-e6a9-c456a5cd7bd1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "UK5w2Geb_3dw",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "25/25 [==============================] - 1s 11ms/step - loss: 0.6810 - accuracy: 0.6637 - val_loss: 0.6696 - val_accuracy: 0.7250\n",
            "Epoch 2/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.6476 - accuracy: 0.7663 - val_loss: 0.6360 - val_accuracy: 0.7500\n",
            "Epoch 3/50\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.6005 - accuracy: 0.7900 - val_loss: 0.5876 - val_accuracy: 0.7500\n",
            "Epoch 4/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.5443 - accuracy: 0.7950 - val_loss: 0.5375 - val_accuracy: 0.7550\n",
            "Epoch 5/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.4907 - accuracy: 0.8087 - val_loss: 0.5013 - val_accuracy: 0.7600\n",
            "Epoch 6/50\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.4524 - accuracy: 0.8213 - val_loss: 0.4799 - val_accuracy: 0.7500\n",
            "Epoch 7/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.4211 - accuracy: 0.8313 - val_loss: 0.4681 - val_accuracy: 0.7700\n",
            "Epoch 8/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.4052 - accuracy: 0.8350 - val_loss: 0.4607 - val_accuracy: 0.7700\n",
            "Epoch 9/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3915 - accuracy: 0.8400 - val_loss: 0.4574 - val_accuracy: 0.7800\n",
            "Epoch 10/50\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3816 - accuracy: 0.8400 - val_loss: 0.4556 - val_accuracy: 0.7750\n",
            "Epoch 11/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3707 - accuracy: 0.8388 - val_loss: 0.4589 - val_accuracy: 0.7650\n",
            "Epoch 12/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3573 - accuracy: 0.8487 - val_loss: 0.4576 - val_accuracy: 0.7750\n",
            "Epoch 13/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3524 - accuracy: 0.8462 - val_loss: 0.4587 - val_accuracy: 0.7700\n",
            "Epoch 14/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3407 - accuracy: 0.8550 - val_loss: 0.4589 - val_accuracy: 0.7850\n",
            "Epoch 15/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3389 - accuracy: 0.8637 - val_loss: 0.4647 - val_accuracy: 0.7500\n",
            "Epoch 16/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3374 - accuracy: 0.8575 - val_loss: 0.4631 - val_accuracy: 0.7550\n",
            "Epoch 17/50\n",
            "25/25 [==============================] - 0s 8ms/step - loss: 0.3308 - accuracy: 0.8600 - val_loss: 0.4662 - val_accuracy: 0.7500\n",
            "Epoch 18/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3163 - accuracy: 0.8625 - val_loss: 0.4675 - val_accuracy: 0.7600\n",
            "Epoch 19/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3197 - accuracy: 0.8675 - val_loss: 0.4710 - val_accuracy: 0.7550\n",
            "Epoch 20/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3140 - accuracy: 0.8725 - val_loss: 0.4711 - val_accuracy: 0.7600\n",
            "Epoch 21/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3034 - accuracy: 0.8700 - val_loss: 0.4713 - val_accuracy: 0.7600\n",
            "Epoch 22/50\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3048 - accuracy: 0.8763 - val_loss: 0.4733 - val_accuracy: 0.7600\n",
            "Epoch 23/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.2966 - accuracy: 0.8788 - val_loss: 0.4752 - val_accuracy: 0.7600\n",
            "Epoch 24/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.2970 - accuracy: 0.8750 - val_loss: 0.4778 - val_accuracy: 0.7550\n",
            "Epoch 25/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.2930 - accuracy: 0.8813 - val_loss: 0.4820 - val_accuracy: 0.7600\n",
            "Epoch 26/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.2931 - accuracy: 0.8725 - val_loss: 0.4827 - val_accuracy: 0.7450\n",
            "Epoch 27/50\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.2842 - accuracy: 0.8850 - val_loss: 0.4830 - val_accuracy: 0.7500\n",
            "Epoch 28/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.2815 - accuracy: 0.8913 - val_loss: 0.4870 - val_accuracy: 0.7500\n",
            "Epoch 29/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.2851 - accuracy: 0.8913 - val_loss: 0.4881 - val_accuracy: 0.7400\n",
            "Epoch 30/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.2807 - accuracy: 0.8850 - val_loss: 0.4911 - val_accuracy: 0.7550\n",
            "Epoch 31/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.2761 - accuracy: 0.8825 - val_loss: 0.4926 - val_accuracy: 0.7450\n",
            "Epoch 32/50\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.2735 - accuracy: 0.8950 - val_loss: 0.4954 - val_accuracy: 0.7500\n",
            "Epoch 33/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.2726 - accuracy: 0.8950 - val_loss: 0.4959 - val_accuracy: 0.7400\n",
            "Epoch 34/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.2685 - accuracy: 0.8975 - val_loss: 0.4995 - val_accuracy: 0.7350\n",
            "Epoch 35/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.2628 - accuracy: 0.8975 - val_loss: 0.5021 - val_accuracy: 0.7400\n",
            "Epoch 36/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.2627 - accuracy: 0.8975 - val_loss: 0.5044 - val_accuracy: 0.7500\n",
            "Epoch 37/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.2605 - accuracy: 0.8963 - val_loss: 0.5080 - val_accuracy: 0.7600\n",
            "Epoch 38/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.2495 - accuracy: 0.9075 - val_loss: 0.5092 - val_accuracy: 0.7500\n",
            "Epoch 39/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.2551 - accuracy: 0.8950 - val_loss: 0.5106 - val_accuracy: 0.7550\n",
            "Epoch 40/50\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.2494 - accuracy: 0.9025 - val_loss: 0.5121 - val_accuracy: 0.7650\n",
            "Epoch 41/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.2469 - accuracy: 0.9062 - val_loss: 0.5150 - val_accuracy: 0.7500\n",
            "Epoch 42/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.2460 - accuracy: 0.9025 - val_loss: 0.5181 - val_accuracy: 0.7550\n",
            "Epoch 43/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.2495 - accuracy: 0.9075 - val_loss: 0.5209 - val_accuracy: 0.7500\n",
            "Epoch 44/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.2384 - accuracy: 0.9025 - val_loss: 0.5285 - val_accuracy: 0.7650\n",
            "Epoch 45/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.2370 - accuracy: 0.9013 - val_loss: 0.5297 - val_accuracy: 0.7500\n",
            "Epoch 46/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.2342 - accuracy: 0.9062 - val_loss: 0.5293 - val_accuracy: 0.7450\n",
            "Epoch 47/50\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.2368 - accuracy: 0.9187 - val_loss: 0.5339 - val_accuracy: 0.7500\n",
            "Epoch 48/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.2321 - accuracy: 0.9075 - val_loss: 0.5360 - val_accuracy: 0.7400\n",
            "Epoch 49/50\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.2349 - accuracy: 0.9125 - val_loss: 0.5410 - val_accuracy: 0.7450\n",
            "Epoch 50/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.2359 - accuracy: 0.9125 - val_loss: 0.5429 - val_accuracy: 0.7400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = history.history['val_accuracy'][-1]\n",
        "error = 1-accuracy\n",
        "print ('Neural Net Accuracy:', accuracy*100,'%')\n"
      ],
      "metadata": {
        "id": "Nq1I9Kq5bEvw",
        "outputId": "c8a0cf0f-801b-4802-fffc-b0e774136b09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Nq1I9Kq5bEvw",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural Net Accuracy: 74.00000095367432 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparison \n",
        "\n"
      ],
      "metadata": {
        "id": "D_7SUeljUR0R"
      },
      "id": "D_7SUeljUR0R"
    }
  ]
}